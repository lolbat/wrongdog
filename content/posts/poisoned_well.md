---
title: "Poisoned well"
date: 2023-02-09T12:30:30-07:00
draft: false
tags:
    - Google
    - Bing
    - OpenAI
    - ChatGPT
    - Search Engines
---

People are, rightly, worried about the impact that systems like ChatGPT will have on the veracity of information in general and our ability to find accurate information on search engines such as Google, Bing and Duck Duck Go. I would like to suggest that this is already a problem and that a relentless AI circle-jerk of content referencing will make most of the internet unusable.

## Battery disposal

Google search pages recently started telling people that it was safe to dispose of their car batteries by [throwing them in the ocean](https://futurism.com/the-byte/google-car-batteries-ocean). Alongside its search results, Google’s search systems also try to create answers for questions posed by search queries. Things like “how can I dispose of car batteries?”. And occasionally, the results so horribly wrong that they get traction and made a mockery of for however long a meme cycle is online. 

This mechanism of creating content to keep people on your web properties is also something that Bing does and so Google’s ridiculous answer to them crept into Bing. Itamar Turner-Trauring [posted screenshots](https://elk.zone/home.social/@itamarst@hachyderm.io/109831444259461095) of Bing returning the same incorrect information, although some people noted that the way you phrased the question on Bing informed the results you received. 

## Health advice

Men’s Journal recently was bought out by a hedge fund that then fired most of the staff and has been replacing their content with “AI” content. Which makes it unsurprising that they posted an article that which gave [incorrect and misleading information](https://futurism.com/neoscope/magazine-mens-journal-errors-ai-health-article) about low testosterone.

The article was rewritten after the chief of medicine at the University of Washington Medical Center pointed out 18 errors in the article. And this was in a piece that was supposedly reviewed before being posted. 

## Sheet music

And it isn’t just algorithms that are causing problems. I recently tried looking for a musical transcription of a piece of Jazz performed by Oscar Peterson. I was able to find quite a few results, but even though the pages specified Peterson by name, the music they were selling was not by him. It was sheet music for the original classical piece that he had interpreted. 

Content like this is being misattributed or misidentified constantly. It is only when someone knows enough about the subject material that they can infer that the product they are being offered isn’t in-fact what they want but is instead incorrectly, or sloppily, categorised. 

## They are all algorithms

OpenAI, Microsoft, Google and others want to talk about how these new systems are AI, but they are not. They are the same types of machine learning systems that tell us that we can throw batteries into the sea and that milk will give us low testosterone. ChatGPT just has more information to use to make up answers and is better at sounding confident about its answers. 

I can get a search result and tell, even with my limited musical knowledge, that a piece of sheet music is not actually from an Oscar Peterson performance. Machine learning systems can’t. They don’t have any intelligence. They can’t verify the “facts” they have been fed. They just produce pleasing content based on other text that was fed into the black box of the machine learning apparatus. 

## That escalated quickly

What worries me the most is that the dystopian internet where “AI” systems have filled it with poisonous inaccuracies is actually already upon us, and that systems like ChatGPT will just worsen it. We already have systems that build damaging article and content. That content was fed into ChatGPT and whatever name Google has for its machine learning system. 

No-one at OpenAI and other labs ever went to the effort to see if they had the rights to use the text, images, video and audio they scrapped to put into their systems. You can be assured that they also didn’t check to see if any of that information was correct. 

We already have vast oceans of dead water on the internet. Poisoned sources that have gone into these systems that are now going to be used to produce even more content, articles and “answers”. I don’t see any way in which that recursive loop of junk won’t eventually make it impossible to find valid and vetted information online. 


